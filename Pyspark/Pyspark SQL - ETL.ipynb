{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c385ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a07ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94560c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "# setMaster() - set spark context manager which is local[cpu_cores]\n",
    "config = SparkConf().setMaster(\"local[4]\").setAppName(\"ETL Pipeline\")\n",
    "sc = SparkContext(conf=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5060f2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"ETL Pipeline\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fbbf9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.8</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ETL Pipeline</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f17540da4a8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c9b42e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hremployeeDF = spark.read.format(\"jdbc\")\\\n",
    ".option(\"url\",\"jdbc:mysql://localhost:3306/hremployeeDB\")\\\n",
    ".option(\"dbtable\",\"HR_Employee\").option(\"user\",\"root\").option(\"password\",\"hadoop@123\")\\\n",
    ".option(\"driver\",\"com.mysql.cj.jdbc.Driver\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c1ffa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+---------+------+---+-------------+-------------+--------------+-----------------+--------------+--------+---------------+----------+------+----------+--------+------+-----------------------+---------------+---------------------+---------------+------------------+\n",
      "|EmployeeID|          Department|             JobRole|Attrition|Gender|Age|MaritalStatus|    Education|EducationField|   BusinessTravel|JobInvolvement|JobLevel|JobSatisfaction|Hourlyrate|Income|Salaryhike|OverTime|Workex|YearsSinceLastPromotion|EmpSatisfaction|TrainingTimesLastYear|WorkLifeBalance|Performance_Rating|\n",
      "+----------+--------------------+--------------------+---------+------+---+-------------+-------------+--------------+-----------------+--------------+--------+---------------+----------+------+----------+--------+------+-----------------------+---------------+---------------------+---------------+------------------+\n",
      "|         1|               Sales|     Sales Executive|      Yes|Female| 41|       Single|      College| Life Sciences|    Travel_Rarely|          High|       2|      Very High|        94|  5993|        11|     Yes|     8|                      0|         Medium|                    0|            Bad|        Excellent\r",
      "|\n",
      "|         2|Research & Develo...|  Research Scientist|       No|  Male| 49|      Married|Below College| Life Sciences|Travel_Frequently|        Medium|       2|         Medium|        61|  5130|        23|      No|    10|                      1|           High|                    3|         Better|      Outstanding\r",
      "|\n",
      "|         3|Research & Develo...|Laboratory Techni...|      Yes|  Male| 37|       Single|      College|         Other|    Travel_Rarely|        Medium|       1|           High|        92|  2090|        15|     Yes|     7|                      0|      Very High|                    3|         Better|        Excellent\r",
      "|\n",
      "|         4|Research & Develo...|  Research Scientist|       No|Female| 33|      Married|       Master| Life Sciences|Travel_Frequently|          High|       1|           High|        56|  2909|        11|     Yes|     8|                      3|      Very High|                    3|         Better|        Excellent\r",
      "|\n",
      "|         5|Research & Develo...|Laboratory Techni...|       No|  Male| 27|      Married|Below College|       Medical|    Travel_Rarely|          High|       1|         Medium|        40|  3468|        12|      No|     6|                      2|            Low|                    3|         Better|        Excellent\r",
      "|\n",
      "|         6|Research & Develo...|Laboratory Techni...|       No|  Male| 32|       Single|      College| Life Sciences|Travel_Frequently|          High|       1|      Very High|        79|  3068|        13|      No|     8|                      3|      Very High|                    2|           Good|        Excellent\r",
      "|\n",
      "|         7|Research & Develo...|Laboratory Techni...|       No|Female| 59|      Married|     Bachelor|       Medical|    Travel_Rarely|     Very High|       1|            Low|        81|  2670|        20|     Yes|    12|                      0|           High|                    3|           Good|      Outstanding\r",
      "|\n",
      "|         8|Research & Develo...|Laboratory Techni...|       No|  Male| 30|     Divorced|Below College| Life Sciences|    Travel_Rarely|          High|       1|           High|        67|  2693|        22|      No|     1|                      0|      Very High|                    2|         Better|      Outstanding\r",
      "|\n",
      "|         9|Research & Develo...|Manufacturing Dir...|       No|  Male| 38|       Single|     Bachelor| Life Sciences|Travel_Frequently|        Medium|       3|           High|        44|  9526|        21|      No|    10|                      1|      Very High|                    2|         Better|      Outstanding\r",
      "|\n",
      "|        10|Research & Develo...|Healthcare Repres...|       No|  Male| 36|      Married|     Bachelor|       Medical|    Travel_Rarely|          High|       2|           High|        94|  5237|        13|      No|    17|                      7|           High|                    3|           Good|        Excellent\r",
      "|\n",
      "|        11|Research & Develo...|Laboratory Techni...|       No|  Male| 35|      Married|     Bachelor|       Medical|    Travel_Rarely|     Very High|       1|         Medium|        84|  2426|        13|      No|     6|                      0|            Low|                    5|         Better|        Excellent\r",
      "|\n",
      "|        12|Research & Develo...|Laboratory Techni...|       No|Female| 29|       Single|      College| Life Sciences|    Travel_Rarely|        Medium|       2|           High|        49|  4193|        12|     Yes|    10|                      0|      Very High|                    3|         Better|        Excellent\r",
      "|\n",
      "|        13|Research & Develo...|  Research Scientist|       No|  Male| 31|     Divorced|Below College| Life Sciences|    Travel_Rarely|          High|       1|           High|        31|  2911|        17|      No|     5|                      4|            Low|                    1|           Good|        Excellent\r",
      "|\n",
      "|        14|Research & Develo...|Laboratory Techni...|       No|  Male| 34|     Divorced|      College|       Medical|    Travel_Rarely|          High|       1|      Very High|        93|  2661|        11|      No|     3|                      1|         Medium|                    2|         Better|        Excellent\r",
      "|\n",
      "|        15|Research & Develo...|Laboratory Techni...|      Yes|  Male| 28|       Single|     Bachelor| Life Sciences|    Travel_Rarely|        Medium|       1|           High|        50|  2028|        14|     Yes|     6|                      0|           High|                    4|         Better|        Excellent\r",
      "|\n",
      "|        16|Research & Develo...|Manufacturing Dir...|       No|Female| 29|     Divorced|       Master| Life Sciences|    Travel_Rarely|     Very High|       3|            Low|        51|  9980|        11|      No|    10|                      8|         Medium|                    1|         Better|        Excellent\r",
      "|\n",
      "|        17|Research & Develo...|  Research Scientist|       No|  Male| 32|     Divorced|      College| Life Sciences|    Travel_Rarely|     Very High|       1|         Medium|        80|  3298|        12|     Yes|     7|                      0|            Low|                    5|           Good|        Excellent\r",
      "|\n",
      "|        18|Research & Develo...|Laboratory Techni...|       No|  Male| 22|     Divorced|      College|       Medical|       Non-Travel|     Very High|       1|      Very High|        96|  2935|        13|     Yes|     1|                      0|      Very High|                    2|           Good|        Excellent\r",
      "|\n",
      "|        19|               Sales|             Manager|       No|Female| 53|      Married|       Master| Life Sciences|    Travel_Rarely|        Medium|       4|      Very High|        78| 15427|        16|      No|    31|                      3|            Low|                    3|         Better|        Excellent\r",
      "|\n",
      "|        20|Research & Develo...|  Research Scientist|       No|  Male| 38|       Single|     Bachelor| Life Sciences|    Travel_Rarely|          High|       1|      Very High|        45|  3944|        11|     Yes|     6|                      1|      Very High|                    3|         Better|        Excellent\r",
      "|\n",
      "+----------+--------------------+--------------------+---------+------+---+-------------+-------------+--------------+-----------------+--------------+--------+---------------+----------+------+----------+--------+------+-----------------------+---------------+---------------------+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hremployeeDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10c68f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Scan JDBCRelation(HR_Employee) [numPartitions=1] [EmployeeID#0,Department#1,JobRole#2,Attrition#3,Gender#4,Age#5,MaritalStatus#6,Education#7,EducationField#8,BusinessTravel#9,JobInvolvement#10,JobLevel#11,JobSatisfaction#12,Hourlyrate#13,Income#14,Salaryhike#15,OverTime#16,Workex#17,YearsSinceLastPromotion#18,EmpSatisfaction#19,TrainingTimesLastYear#20,WorkLifeBalance#21,Performance_Rating#22] PushedFilters: [], ReadSchema: struct<EmployeeID:int,Department:string,JobRole:string,Attrition:string,Gender:string,Age:int,Mar...\n"
     ]
    }
   ],
   "source": [
    "# show physical plan of execution which is known as DAG.\n",
    "hremployeeDF.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7babd9",
   "metadata": {},
   "source": [
    "### Materialized view of table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc63c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "hremployeeDF.createOrReplaceTempView(\"hremployee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ceb281",
   "metadata": {},
   "source": [
    "#### Display shape of hr employee table\n",
    "    * show no of rows and no of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02811b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "008cc84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_nos = len(hremployeeDF.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd258014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|rows|columns|\n",
      "+----+-------+\n",
      "|1469|     23|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"\"\"\n",
    "select count(*) as rows, {col_nos} as columns from hremployee\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9632e6c1",
   "metadata": {},
   "source": [
    "*  This will not work here it will only mysql\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "select count(*) from information_schema.columns WHERE table_name =\"HR_Employee\"\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdb745e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "|          EmployeeID|      int|   null|\n",
      "|          Department|   string|   null|\n",
      "|             JobRole|   string|   null|\n",
      "|           Attrition|   string|   null|\n",
      "|              Gender|   string|   null|\n",
      "|                 Age|      int|   null|\n",
      "|       MaritalStatus|   string|   null|\n",
      "|           Education|   string|   null|\n",
      "|      EducationField|   string|   null|\n",
      "|      BusinessTravel|   string|   null|\n",
      "|      JobInvolvement|   string|   null|\n",
      "|            JobLevel|      int|   null|\n",
      "|     JobSatisfaction|   string|   null|\n",
      "|          Hourlyrate|      int|   null|\n",
      "|              Income|      int|   null|\n",
      "|          Salaryhike|      int|   null|\n",
      "|            OverTime|   string|   null|\n",
      "|              Workex|      int|   null|\n",
      "|YearsSinceLastPro...|      int|   null|\n",
      "|     EmpSatisfaction|   string|   null|\n",
      "|TrainingTimesLast...|      int|   null|\n",
      "|     WorkLifeBalance|   string|   null|\n",
      "|  Performance_Rating|   string|   null|\n",
      "+--------------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "describe hremployee\n",
    "\"\"\").show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef623a1",
   "metadata": {},
   "source": [
    "#### 2. write a query to show first 3 employees from each job role to join the company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52d04fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----+\n",
      "|EmployeeID|             JobRole|RANK|\n",
      "+----------+--------------------+----+\n",
      "|         1|     Sales Executive|   1|\n",
      "|        28|     Sales Executive|   2|\n",
      "|        40|     Sales Executive|   3|\n",
      "|         9|Manufacturing Dir...|   1|\n",
      "|        16|Manufacturing Dir...|   2|\n",
      "|        21|Manufacturing Dir...|   3|\n",
      "|         3|Laboratory Techni...|   1|\n",
      "|         5|Laboratory Techni...|   2|\n",
      "|         6|Laboratory Techni...|   3|\n",
      "|        22|Sales Representative|   1|\n",
      "|        34|Sales Representative|   2|\n",
      "|        37|Sales Representative|   3|\n",
      "|        10|Healthcare Repres...|   1|\n",
      "|        29|Healthcare Repres...|   2|\n",
      "|        32|Healthcare Repres...|   3|\n",
      "|         2|  Research Scientist|   1|\n",
      "|         4|  Research Scientist|   2|\n",
      "|        13|  Research Scientist|   3|\n",
      "|        19|             Manager|   1|\n",
      "|        26|             Manager|   2|\n",
      "+----------+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" \n",
    "select * from\n",
    "(select EmployeeID, JobRole, RANK() OVER(partition by JobRole order by EmployeeID ) AS RANK\n",
    "from hremployee) as _ where RANK < 4\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe53a4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EmployeeID',\n",
       " 'Department',\n",
       " 'JobRole',\n",
       " 'Attrition',\n",
       " 'Gender',\n",
       " 'Age',\n",
       " 'MaritalStatus',\n",
       " 'Education',\n",
       " 'EducationField',\n",
       " 'BusinessTravel',\n",
       " 'JobInvolvement',\n",
       " 'JobLevel',\n",
       " 'JobSatisfaction',\n",
       " 'Hourlyrate',\n",
       " 'Income',\n",
       " 'Salaryhike',\n",
       " 'OverTime',\n",
       " 'Workex',\n",
       " 'YearsSinceLastPromotion',\n",
       " 'EmpSatisfaction',\n",
       " 'TrainingTimesLastYear',\n",
       " 'WorkLifeBalance',\n",
       " 'Performance_Rating']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hremployeeDF.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecfad89",
   "metadata": {},
   "source": [
    "#### 3. Write a query to show top 3 employee from each job role earning  highest salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ce70c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+----+\n",
      "|             JobRole|Income|RANK|\n",
      "+--------------------+------+----+\n",
      "|     Sales Executive| 13872|   1|\n",
      "|     Sales Executive| 13770|   2|\n",
      "|     Sales Executive| 13758|   3|\n",
      "|Manufacturing Dir...| 13973|   1|\n",
      "|Manufacturing Dir...| 13826|   2|\n",
      "|Manufacturing Dir...| 13726|   3|\n",
      "|Laboratory Techni...|  7403|   1|\n",
      "|Laboratory Techni...|  6782|   2|\n",
      "|Laboratory Techni...|  6674|   3|\n",
      "|Sales Representative|  6632|   1|\n",
      "|Sales Representative|  5405|   2|\n",
      "|Sales Representative|  4502|   3|\n",
      "|Healthcare Repres...| 13966|   1|\n",
      "|Healthcare Repres...| 13964|   2|\n",
      "|Healthcare Repres...| 13734|   3|\n",
      "|  Research Scientist|  9724|   1|\n",
      "|  Research Scientist|  6962|   2|\n",
      "|  Research Scientist|  6854|   3|\n",
      "|             Manager| 19999|   1|\n",
      "|             Manager| 19943|   2|\n",
      "+--------------------+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" \n",
    "select * from\n",
    "(select  JobRole,Income, RANK() OVER(partition by JobRole order by Income desc) AS RANK\n",
    "from hremployee) as _ where RANK < 4\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5115ba",
   "metadata": {},
   "source": [
    "#### 4. show top 3 highest package from overall job role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93c20750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+----+\n",
      "|          JobRole|Income|RANK|\n",
      "+-----------------+------+----+\n",
      "|          Manager| 19999|   1|\n",
      "|Research Director| 19973|   2|\n",
      "|          Manager| 19943|   3|\n",
      "+-----------------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" \n",
    "select * from\n",
    "(select  JobRole,Income, RANK() OVER(order by Income desc) AS RANK\n",
    "from hremployee) as _ where RANK < 4\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d273388a",
   "metadata": {},
   "source": [
    "#### LAG()\n",
    "\n",
    "5. show employee in order of ascending order with respect to employee income compared to previous income for each job role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ae352338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------+-----+-----+\n",
      "|EmployeeID|             JobRole|Income| prev| diff|\n",
      "+----------+--------------------+------+-----+-----+\n",
      "|        10|Healthcare Repres...|  5237| null| null|\n",
      "|       285|Healthcare Repres...|  4741|13496|-8755|\n",
      "|      1183|Healthcare Repres...|  6842|13966|-7124|\n",
      "|      1157|Healthcare Repres...|  4148|11245|-7097|\n",
      "|       205|Healthcare Repres...|  6673|13734|-7061|\n",
      "|       677|Healthcare Repres...|  4014|10552|-6538|\n",
      "|       397|Healthcare Repres...|  4522|10965|-6443|\n",
      "|       833|Healthcare Repres...|  5731|12169|-6438|\n",
      "|      1065|Healthcare Repres...|  4035|10466|-6431|\n",
      "|       745|Healthcare Repres...|  4777|10999|-6222|\n",
      "|       736|Healthcare Repres...|  4240|10388|-6148|\n",
      "|      1098|Healthcare Repres...|  4069|10124|-6055|\n",
      "|        89|Healthcare Repres...|  4152|10096|-5944|\n",
      "|       489|Healthcare Repres...|  4089| 9824|-5735|\n",
      "|       929|Healthcare Repres...|  7978|13577|-5599|\n",
      "|       105|Healthcare Repres...|  5163|10673|-5510|\n",
      "|       267|Healthcare Repres...|  5582|10938|-5356|\n",
      "|      1231|Healthcare Repres...|  5562|10748|-5186|\n",
      "|       555|Healthcare Repres...|  6811|11103|-4292|\n",
      "|      1045|Healthcare Repres...|  6651|10851|-4200|\n",
      "|       527|Healthcare Repres...|  4553| 8621|-4068|\n",
      "|       334|Healthcare Repres...|  9985|13964|-3979|\n",
      "|       373|Healthcare Repres...|  6540|10496|-3956|\n",
      "|       309|Healthcare Repres...|  5660| 9613|-3953|\n",
      "|      1131|Healthcare Repres...|  5063| 8853|-3790|\n",
      "|        32|Healthcare Repres...|  6465|10248|-3783|\n",
      "|      1425|Healthcare Repres...|  4878| 8633|-3755|\n",
      "|      1008|Healthcare Repres...|  7553|10920|-3367|\n",
      "|       357|Healthcare Repres...|  6781| 9985|-3204|\n",
      "|       791|Healthcare Repres...|  7119|10322|-3203|\n",
      "|       460|Healthcare Repres...|  6811| 9824|-3013|\n",
      "|      1214|Healthcare Repres...|  7879|10883|-3004|\n",
      "|      1407|Healthcare Repres...|  4617| 7510|-2893|\n",
      "|        94|Healthcare Repres...| 10673|13503|-2830|\n",
      "|      1287|Healthcare Repres...|  5538| 8321|-2783|\n",
      "|      1299|Healthcare Repres...|  6513| 8926|-2413|\n",
      "|       768|Healthcare Repres...|  4107| 6385|-2278|\n",
      "|       979|Healthcare Repres...|  6377| 8500|-2123|\n",
      "|      1304|Healthcare Repres...|  4448| 6513|-2065|\n",
      "|       209|Healthcare Repres...|  4876| 6673|-1797|\n",
      "|       558|Healthcare Repres...|  5093| 6811|-1718|\n",
      "|       268|Healthcare Repres...|  4000| 5582|-1582|\n",
      "|      1199|Healthcare Repres...|  5347| 6842|-1495|\n",
      "|       550|Healthcare Repres...|  6142| 7625|-1483|\n",
      "|       716|Healthcare Repres...|  5488| 6949|-1461|\n",
      "|      1352|Healthcare Repres...|  5033| 6384|-1351|\n",
      "|      1123|Healthcare Repres...|  6142| 7441|-1299|\n",
      "|      1259|Healthcare Repres...|  5294| 6294|-1000|\n",
      "|       943|Healthcare Repres...|  7094| 7978| -884|\n",
      "|       164|Healthcare Repres...|  9439|10312| -873|\n",
      "|       573|Healthcare Repres...|  4335| 5093| -758|\n",
      "|       472|Healthcare Repres...|  9824|10527| -703|\n",
      "|      1398|Healthcare Repres...|  5968| 6667| -699|\n",
      "|      1456|Healthcare Repres...|  5689| 6306| -617|\n",
      "|       848|Healthcare Repres...|  5343| 5731| -388|\n",
      "|       651|Healthcare Repres...|  5562| 5933| -371|\n",
      "|       618|Healthcare Repres...|  5933| 6288| -355|\n",
      "|       904|Healthcare Repres...|  6623| 6812| -189|\n",
      "|       583|Healthcare Repres...|  4244| 4335|  -91|\n",
      "|       303|Healthcare Repres...|  5661| 5745|  -84|\n",
      "|      1387|Healthcare Repres...|  5373| 5399|  -26|\n",
      "|       361|Healthcare Repres...|  6755| 6781|  -26|\n",
      "|       897|Healthcare Repres...|  6812| 6833|  -21|\n",
      "|       414|Healthcare Repres...|  4523| 4522|    1|\n",
      "|       785|Healthcare Repres...|  8823| 8722|  101|\n",
      "|        65|Healthcare Repres...| 10096| 9884|  212|\n",
      "|       984|Healthcare Repres...|  6687| 6377|  310|\n",
      "|      1362|Healthcare Repres...|  5399| 5033|  366|\n",
      "|      1093|Healthcare Repres...| 10124| 9715|  409|\n",
      "|      1261|Healthcare Repres...|  5811| 5294|  517|\n",
      "|       795|Healthcare Repres...|  7756| 7119|  637|\n",
      "|      1250|Healthcare Repres...|  6294| 5562|  732|\n",
      "|       525|Healthcare Repres...|  8621| 7725|  896|\n",
      "|       288|Healthcare Repres...|  5745| 4741| 1004|\n",
      "|       665|Healthcare Repres...|  6586| 5562| 1024|\n",
      "|       695|Healthcare Repres...|  6949| 5855| 1094|\n",
      "|      1090|Healthcare Repres...|  9715| 8606| 1109|\n",
      "|      1388|Healthcare Repres...|  6667| 5373| 1294|\n",
      "|      1294|Healthcare Repres...|  6870| 5538| 1332|\n",
      "|       959|Healthcare Repres...|  8500| 7094| 1406|\n",
      "|      1441|Healthcare Repres...|  6306| 4878| 1428|\n",
      "|       896|Healthcare Repres...|  6833| 5343| 1490|\n",
      "|       786|Healthcare Repres...| 10322| 8823| 1499|\n",
      "|      1399|Healthcare Repres...|  7510| 5968| 1542|\n",
      "|       252|Healthcare Repres...| 10938| 9396| 1542|\n",
      "|       746|Healthcare Repres...|  6385| 4777| 1608|\n",
      "|      1203|Healthcare Repres...|  7005| 5347| 1658|\n",
      "|       814|Healthcare Repres...| 12169|10445| 1724|\n",
      "|       691|Healthcare Repres...|  5855| 4014| 1841|\n",
      "|      1324|Healthcare Repres...|  6384| 4448| 1936|\n",
      "|       606|Healthcare Repres...|  6288| 4244| 2044|\n",
      "|      1298|Healthcare Repres...|  8926| 6870| 2056|\n",
      "|       440|Healthcare Repres...|  9824| 7632| 2192|\n",
      "|      1081|Healthcare Repres...|  8606| 6388| 2218|\n",
      "|       111|Healthcare Repres...|  7484| 5163| 2321|\n",
      "|      1074|Healthcare Repres...|  6388| 4035| 2353|\n",
      "|      1278|Healthcare Repres...|  8321| 5811| 2510|\n",
      "|       807|Healthcare Repres...| 10445| 7756| 2689|\n",
      "|      1125|Healthcare Repres...|  8853| 6142| 2711|\n",
      "|       127|Healthcare Repres...| 10312| 7484| 2828|\n",
      "+----------+--------------------+------+-----+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" \n",
    "select *, (Income-prev) as diff from\n",
    "(select  EmployeeID, JobRole,Income, \n",
    "LAG(Income,1) OVER(partition by JobRole order by EmployeeID asc) AS prev\n",
    "from hremployee) as _  order by JobRole,diff\n",
    "\"\"\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "86735ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+------+-----+-----+\n",
      "|EmployeeID|        JobRole|Income| prev| diff|\n",
      "+----------+---------------+------+-----+-----+\n",
      "|         1|Sales Executive|  5993|    0| 5993|\n",
      "|        28|Sales Executive|  6825| 5993|  832|\n",
      "|        40|Sales Executive|  5376| 6825|-1449|\n",
      "|        44|Sales Executive|  8726| 5376| 3350|\n",
      "|        47|Sales Executive|  4568| 8726|-4158|\n",
      "|        49|Sales Executive|  5772| 4568| 1204|\n",
      "|        53|Sales Executive|  5454| 5772| -318|\n",
      "|        55|Sales Executive|  4157| 5454|-1297|\n",
      "|        57|Sales Executive|  9069| 4157| 4912|\n",
      "|        64|Sales Executive|  7637| 9069|-1432|\n",
      "|        71|Sales Executive|  5473| 7637|-2164|\n",
      "|        77|Sales Executive|  4312| 5473|-1161|\n",
      "|        83|Sales Executive| 10239| 4312| 5927|\n",
      "|        90|Sales Executive|  9619|10239| -620|\n",
      "|        92|Sales Executive|  5441| 9619|-4178|\n",
      "|        93|Sales Executive|  5209| 5441| -232|\n",
      "|        95|Sales Executive|  5010| 5209| -199|\n",
      "|        97|Sales Executive|  4999| 5010|  -11|\n",
      "|        98|Sales Executive|  4221| 4999| -778|\n",
      "|        99|Sales Executive| 13872| 4221| 9651|\n",
      "+----------+---------------+------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select  EmployeeID, JobRole,Income, LAG(Income,1,0) OVER(partition by JobRole order by EmployeeID asc) as prev,\n",
    "Income -LAG(Income,1,0) OVER(partition by JobRole order by EmployeeID asc) AS diff\n",
    "from hremployee\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63353351",
   "metadata": {},
   "source": [
    "#### 6. Lead()\n",
    "* Rows next record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3da61174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+---+------+------+-----------+\n",
      "|employeeid|department|        jobrole|age|gender|income|next_income|\n",
      "+----------+----------+---------------+---+------+------+-----------+\n",
      "|         1|     Sales|Sales Executive| 41|Female|  5993|       5376|\n",
      "|        28|     Sales|Sales Executive| 42|  Male|  6825|       8726|\n",
      "|        40|     Sales|Sales Executive| 33|Female|  5376|       4568|\n",
      "|        44|     Sales|Sales Executive| 27|  Male|  8726|       5772|\n",
      "|        47|     Sales|Sales Executive| 34|  Male|  4568|       5454|\n",
      "|        49|     Sales|Sales Executive| 46|  Male|  5772|       4157|\n",
      "|        53|     Sales|Sales Executive| 44|Female|  5454|       9069|\n",
      "|        55|     Sales|Sales Executive| 26|Female|  4157|       7637|\n",
      "|        57|     Sales|Sales Executive| 35|  Male|  9069|       5473|\n",
      "|        64|     Sales|Sales Executive| 59|Female|  7637|       4312|\n",
      "|        71|     Sales|Sales Executive| 59|Female|  5473|      10239|\n",
      "|        77|     Sales|Sales Executive| 35|  Male|  4312|       9619|\n",
      "|        83|     Sales|Sales Executive| 55|  Male| 10239|       5441|\n",
      "|        90|     Sales|Sales Executive| 46|  Male|  9619|       5209|\n",
      "|        92|     Sales|Sales Executive| 51|  Male|  5441|       5010|\n",
      "|        93|     Sales|Sales Executive| 30|Female|  5209|       4999|\n",
      "|        95|     Sales|Sales Executive| 32|  Male|  5010|       4221|\n",
      "|        97|     Sales|Sales Executive| 24|Female|  4999|      13872|\n",
      "|        98|     Sales|Sales Executive| 28|  Male|  4221|       5744|\n",
      "|        99|     Sales|Sales Executive| 58|  Male| 13872|       7428|\n",
      "+----------+----------+---------------+---+------+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select employeeid, department, jobrole, age, gender,income,\n",
    "LEAD(income,2,0) over(partition by JobRole order by EmployeeID) as next_income\n",
    "from hremployee\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cba51e3",
   "metadata": {},
   "source": [
    "#### NTILE()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4628ac",
   "metadata": {},
   "source": [
    "* dividing records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "95f548b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+---+------+------+----------------+\n",
      "|employeeid|          department|             jobrole|age|gender|income|SALARY_QUARTILES|\n",
      "+----------+--------------------+--------------------+---+------+------+----------------+\n",
      "|       514|Research & Develo...|  Research Scientist| 20|  Male|  1009|               1|\n",
      "|       728|Research & Develo...|  Research Scientist| 18|  Male|  1051|               1|\n",
      "|       765|               Sales|Sales Representative| 28|  Male|  1052|               1|\n",
      "|      1338|               Sales|Sales Representative| 30|  Male|  1081|               1|\n",
      "|      1365|               Sales|Sales Representative| 29|  Male|  1091|               1|\n",
      "|       178|Research & Develo...|Laboratory Techni...| 19|  Male|  1102|               1|\n",
      "|       912|               Sales|Sales Representative| 25|  Male|  1118|               1|\n",
      "|      1402|Research & Develo...|Laboratory Techni...| 31|Female|  1129|               1|\n",
      "|       302|               Sales|Sales Representative| 18|Female|  1200|               1|\n",
      "|       911|Research & Develo...|  Research Scientist| 23|  Male|  1223|               1|\n",
      "|        24|Research & Develo...|  Research Scientist| 21|  Male|  1232|               1|\n",
      "|      1017|Research & Develo...|  Research Scientist| 31|Female|  1261|               1|\n",
      "|      1053|Research & Develo...|  Research Scientist| 30|  Male|  1274|               1|\n",
      "|       516|Research & Develo...|Laboratory Techni...| 35|  Male|  1281|               1|\n",
      "|      1013|               Sales|Sales Representative| 31|Female|  1359|               1|\n",
      "|      1205|Research & Develo...|Laboratory Techni...| 32|  Male|  1393|               1|\n",
      "|       778|Research & Develo...|Laboratory Techni...| 21|Female|  1416|               1|\n",
      "|       297|Research & Develo...|Laboratory Techni...| 18|  Male|  1420|               1|\n",
      "|       150|Research & Develo...|Laboratory Techni...| 19|Female|  1483|               1|\n",
      "|      1311|Research & Develo...|  Research Scientist| 18|Female|  1514|               1|\n",
      "+----------+--------------------+--------------------+---+------+------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select employeeid, department, jobrole, age, gender,income,\n",
    "NTILE(4) over(order by INCOME) as SALARY_QUARTILES\n",
    "from hremployee\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec629d1f",
   "metadata": {},
   "source": [
    "#### Find no of employees in each percentile group 0-25th, 25th-50, 50-75,75-100 using percentile rank, case - when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7521d415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Groups|count|\n",
      "+------+-----+\n",
      "|75-100|  369|\n",
      "| 25-50|  366|\n",
      "| 50-75|  367|\n",
      "|  0-25|  367|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT Groups,count(*) as count from\n",
    "\n",
    "(SELECT *, \n",
    "CASE \n",
    "WHEN percent<0.25 then '0-25'\n",
    "WHEN percent<0.50 then '25-50'\n",
    "WHEN percent<0.75 then '50-75'\n",
    "else '75-100'\n",
    "END AS Groups FROM\n",
    "(select employeeid, income,\n",
    "PERCENT_RANK() over(PARTITION BY Department order by INCOME) as percent\n",
    "from hremployee) AS _  ) \n",
    "as __ group by Groups\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1416c9b1",
   "metadata": {},
   "source": [
    "### Hive Integration with Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f8f60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6cf3bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13281 ResourceManager\n",
      "13014 SecondaryNameNode\n",
      "13448 NodeManager\n",
      "12587 NameNode\n",
      "492 Jps\n",
      "413 SparkSubmit\n",
      "12782 DataNode\n"
     ]
    }
   ],
   "source": [
    "!jps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc03e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark integration with Hive warehouse.\n",
    "# config name for hive - integration property-name = spark.sql.warehouse.dir\" \n",
    "# value = \"/user/hive/warehouse\"\n",
    "spark = (SparkSession.builder.appName(\"Pyspark-Hive-Integration\")\n",
    "        .config(\"spark.sql.warehouse.dir\",\"/user/hive/warehouse\")\n",
    "        .enableHiveSupport().getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c91b8853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|databaseName|\n",
      "+------------+\n",
      "|     default|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37c49141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "create database if not exists airlines\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04b04721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|databaseName|\n",
      "+------------+\n",
      "|    airlines|\n",
      "|     default|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d062a5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "use airlines\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97b6d17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cf7ac27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "create table if not exists flights(DayofMonth int,DayOfWeek int,\n",
    "Carrier varchar(20), OriginAirportID int, DestAirportID int, DepDelay int, ArrDelay int)\n",
    "row format delimited \n",
    "fields terminated by ','\n",
    "linEs terminated by '\\n'\n",
    "STORED AS TEXTFILE\n",
    "TBLPROPERTIES('skip.header.line.count'='1')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b405ca3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|airlines|  flights|      false|\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "851c864c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "load data local inpath '/home/hadoop/Downloads/raw_flight_data1.csv'\n",
    "overwrite into table flights\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "565d85ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "create table if not exists airports(airport_id int,city varchar(50), state varchar(50),name varchAr(100)\n",
    ")\n",
    "row format delimited \n",
    "fields terminated by ','\n",
    "linEs terminated by '\\n'\n",
    "STORED AS TEXTFILE\n",
    "TBLPROPERTIES('skip.header.line.count'='1')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b1c59ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|airlines| airports|      false|\n",
      "|airlines|  flights|      false|\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b1f9c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "load data local inpath '/home/hadoop/Downloads/airports1.csv'\n",
    "overwrite into table airports\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "123bd985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     366|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from airports\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50a9c126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 2719419|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from flights\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "510ed08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|       1|\n",
      "|        19|        5|     DL|          14869|        12478|       0|      -8|\n",
      "|        19|        5|     DL|          14057|        14869|      -4|     -15|\n",
      "|        19|        5|     DL|          15016|        11433|      28|      24|\n",
      "|        19|        5|     DL|          11193|        12892|      -6|     -11|\n",
      "|        19|        5|     DL|          10397|        15016|      -1|     -19|\n",
      "|        19|        5|     DL|          15016|        10397|       0|      -1|\n",
      "|        19|        5|     DL|          10397|        14869|      15|      24|\n",
      "|        19|        5|     DL|          10397|        10423|      33|      34|\n",
      "|        19|        5|     DL|          11278|        10397|     323|     322|\n",
      "|        19|        5|     DL|          14107|        13487|      -7|     -13|\n",
      "|        19|        5|     DL|          11433|        11298|      22|      41|\n",
      "|        19|        5|     DL|          11298|        11433|      40|      20|\n",
      "|        19|        5|     DL|          11433|        12892|      -2|      -7|\n",
      "|        19|        5|     DL|          10397|        12451|      71|      75|\n",
      "|        19|        5|     DL|          12451|        10397|      75|      57|\n",
      "|        19|        5|     DL|          12953|        10397|      -1|      10|\n",
      "|        19|        5|     DL|          11433|        12953|      -3|     -10|\n",
      "|        19|        5|     DL|          10397|        14771|      31|      38|\n",
      "|        19|        5|     DL|          13204|        10397|       8|      25|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from flights\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065dcc2f",
   "metadata": {},
   "source": [
    "### 1. Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65664a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_df = spark.table(\"airlines.flights\")\n",
    "airports_df = spark.table(\"airlines.airports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ba67cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----+--------------------+\n",
      "|airport_id|       city|state|                name|\n",
      "+----------+-----------+-----+--------------------+\n",
      "|     10165|Adak Island|   AK|                Adak|\n",
      "|     10299|  Anchorage|   AK|Ted Stevens Ancho...|\n",
      "|     10304|      Aniak|   AK|       Aniak Airport|\n",
      "|     10754|     Barrow|   AK|Wiley Post/Will R...|\n",
      "|     10551|     Bethel|   AK|      Bethel Airport|\n",
      "|     10926|    Cordova|   AK|Merle K Mudhole S...|\n",
      "|     14709|  Deadhorse|   AK|   Deadhorse Airport|\n",
      "|     11336| Dillingham|   AK|  Dillingham Airport|\n",
      "|     11630|  Fairbanks|   AK|Fairbanks Interna...|\n",
      "|     11997|   Gustavus|   AK|    Gustavus Airport|\n",
      "|     12523|     Juneau|   AK|Juneau International|\n",
      "|     12819|  Ketchikan|   AK|Ketchikan Interna...|\n",
      "|     10245|King Salmon|   AK| King Salmon Airport|\n",
      "|     10170|     Kodiak|   AK|      Kodiak Airport|\n",
      "|     13970|   Kotzebue|   AK| Ralph Wien Memorial|\n",
      "|     13873|       Nome|   AK|        Nome Airport|\n",
      "|     14256| Petersburg|   AK|Petersburg James ...|\n",
      "|     14828|      Sitka|   AK|Sitka Rocky Gutie...|\n",
      "|     12807| St. Mary's|   AK|  St. Mary's Airport|\n",
      "|     11445|   Unalaska|   AK|    Unalaska Airport|\n",
      "+----------+-----------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e129028d",
   "metadata": {},
   "source": [
    "###  2. Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "beaef645",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_join = flight_df.join(airports_df, on = flight_df.OriginAirportID == airports_df.airport_id,how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a8bc02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+----------+--------------+-----+--------------------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|airport_id|          city|state|                name|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+----------+--------------+-----+--------------------+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|       1|     11433|       Detroit|   MI|Detroit Metro Way...|\n",
      "|        19|        5|     DL|          14869|        12478|       0|      -8|     14869|Salt Lake City|   UT|Salt Lake City In...|\n",
      "|        19|        5|     DL|          14057|        14869|      -4|     -15|     14057|      Portland|   OR|Portland Internat...|\n",
      "|        19|        5|     DL|          15016|        11433|      28|      24|     15016|     St. Louis|   MO|Lambert-St. Louis...|\n",
      "|        19|        5|     DL|          11193|        12892|      -6|     -11|     11193|    Cincinnati|   OH|Cincinnati/Northe...|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+----------+--------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_join.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1899eb9a",
   "metadata": {},
   "source": [
    "### 3. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c684ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_join= flights_join.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4050e684",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_join.write.parquet(\"file:///home/hadoop/Downloads/flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32d269a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a parquet file format\n",
    "flights_parquet_df = spark.read.parquet(\"file:///home/hadoop/Downloads/flights/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12ee4708",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_join.write.parquet(\"/flights1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2bcfc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partitioning\n",
    "flights_join.write.partitionBy(\"Carrier\").parquet(\"/airlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7bb88097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucketing\n",
    "flights_join.write.bucketBy(col = 'state', numBuckets = 50).format(\"csv\").saveAsTable(\"bucketed_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d7dbe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_join.write.partitionBy(\"Carrier\").bucketBy(col = 'state', numBuckets = 30).format(\"parquet\")\\\n",
    ".saveAsTable(\"part_bucket_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e0a1cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|Carrier|count(1)|\n",
      "+-------+--------+\n",
      "|     UA|  122443|\n",
      "|     AA|  124037|\n",
      "|     EV|   46563|\n",
      "|     B6|   51381|\n",
      "|     DL|  134724|\n",
      "|     OO|   69785|\n",
      "|     F9|    9811|\n",
      "|     YV|   14612|\n",
      "|     US|  100668|\n",
      "|     MQ|   45926|\n",
      "|     HA|    4962|\n",
      "|     AS|   28796|\n",
      "|     FL|   28053|\n",
      "|     VX|   14683|\n",
      "|     WN|  216101|\n",
      "|     9E|   36030|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# not qurying from materialized table but actual table\n",
    "spark.sql(\"select Carrier, count(*) from part_bucket_table group by Carrier\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b6cccd",
   "metadata": {},
   "source": [
    "### Loading on MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1f3ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_properties = {\n",
    "    'user':\"root\",\n",
    "    'password':\"hadoop@123\",\n",
    "    'driver':'com.mysql.cj.jdbc.Driver'\n",
    "}\n",
    "\n",
    "flights_join.write.jdbc(url = 'jdbc:mysql://localhost:3306/flights', table = \"airlines\", \n",
    "                       mode = \"overwrite\", properties = connection_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0be0da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8b29b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e60f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
