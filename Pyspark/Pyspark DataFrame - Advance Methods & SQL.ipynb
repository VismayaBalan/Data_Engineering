{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d682f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.8</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b0482a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.8</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f1760407b00>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "468c696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df = spark.read.json(\"file:///home/hadoop/Downloads/People.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83d6db42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------+------+---+---------+------+\n",
      "|     city|    country|first_name|gender| id|last_name|salary|\n",
      "+---------+-----------+----------+------+---+---------+------+\n",
      "|Mulyosari|  Indonesia|     Valma|Female|  1|     Sans|983107|\n",
      "|  Niihama|      Japan|     Paolo|  Male|  2|   Kiddie|649173|\n",
      "|Dū Qal‘ah|Afghanistan|    Miltie|  Male|  3| De Zuani|352898|\n",
      "|   Iberia|       Peru|    Jarrid|  Male|  4| Dalziell|170398|\n",
      "| La Ronge|     Canada| Reinaldos|  Male|  5|   Keeffe|440989|\n",
      "+---------+-----------+----------+------+---+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af739094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bf11a2",
   "metadata": {},
   "source": [
    "####  1. Create a user defined schema for fields of DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5560c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType, FloatType, StringType, StructType, StructField\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "557c34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"id\", IntegerType(), True),\n",
    "        StructField(\"first_name\", StringType(), True),\n",
    "        StructField(\"last_name\", StringType(), True),\n",
    "        StructField(\"gender\", StringType(), True),\n",
    "        StructField(\"salary\", LongType(), True),\n",
    "        StructField(\"city\", StringType(), True),\n",
    "        StructField(\"country\", StringType(), True)\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5ed2819",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df = spark.read.schema(schema).json(\"file:///home/hadoop/Downloads/People.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a867ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "131afd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+-------+---+-------+--------+---------+-------+------------+----+--------+-----+-----+--------+--------+---+\n",
      "|age|balance|campaign|contact|day|default|duration|education|housing|         job|loan| marital|month|pdays|poutcome|previous|  y|\n",
      "+---+-------+--------+-------+---+-------+--------+---------+-------+------------+----+--------+-----+-----+--------+--------+---+\n",
      "| 58|   2143|       1|unknown|  5|     no|     261| tertiary|    yes|  management|  no| married|  may|   -1| unknown|       0| no|\n",
      "| 44|     29|       1|unknown|  5|     no|     151|secondary|    yes|  technician|  no|  single|  may|   -1| unknown|       0| no|\n",
      "| 33|      2|       1|unknown|  5|     no|      76|secondary|    yes|entrepreneur| yes| married|  may|   -1| unknown|       0| no|\n",
      "| 47|   1506|       1|unknown|  5|     no|      92|  unknown|    yes| blue-collar|  no| married|  may|   -1| unknown|       0| no|\n",
      "| 33|      1|       1|unknown|  5|     no|     198|  unknown|     no|     unknown|  no|  single|  may|   -1| unknown|       0| no|\n",
      "| 35|    231|       1|unknown|  5|     no|     139| tertiary|    yes|  management|  no| married|  may|   -1| unknown|       0| no|\n",
      "| 28|    447|       1|unknown|  5|     no|     217| tertiary|    yes|  management| yes|  single|  may|   -1| unknown|       0| no|\n",
      "| 42|      2|       1|unknown|  5|    yes|     380| tertiary|    yes|entrepreneur|  no|divorced|  may|   -1| unknown|       0| no|\n",
      "| 58|    121|       1|unknown|  5|     no|      50|  primary|    yes|     retired|  no| married|  may|   -1| unknown|       0| no|\n",
      "| 43|    593|       1|unknown|  5|     no|      55|secondary|    yes|  technician|  no|  single|  may|   -1| unknown|       0| no|\n",
      "| 41|    270|       1|unknown|  5|     no|     222|secondary|    yes|      admin.|  no|divorced|  may|   -1| unknown|       0| no|\n",
      "| 29|    390|       1|unknown|  5|     no|     137|secondary|    yes|      admin.|  no|  single|  may|   -1| unknown|       0| no|\n",
      "| 53|      6|       1|unknown|  5|     no|     517|secondary|    yes|  technician|  no| married|  may|   -1| unknown|       0| no|\n",
      "| 58|     71|       1|unknown|  5|     no|      71|  unknown|    yes|  technician|  no| married|  may|   -1| unknown|       0| no|\n",
      "| 57|    162|       1|unknown|  5|     no|     174|secondary|    yes|    services|  no| married|  may|   -1| unknown|       0| no|\n",
      "| 51|    229|       1|unknown|  5|     no|     353|  primary|    yes|     retired|  no| married|  may|   -1| unknown|       0| no|\n",
      "| 45|     13|       1|unknown|  5|     no|      98|  unknown|    yes|      admin.|  no|  single|  may|   -1| unknown|       0| no|\n",
      "| 57|     52|       1|unknown|  5|     no|      38|  primary|    yes| blue-collar|  no| married|  may|   -1| unknown|       0| no|\n",
      "| 60|     60|       1|unknown|  5|     no|     219|  primary|    yes|     retired|  no| married|  may|   -1| unknown|       0| no|\n",
      "| 33|      0|       1|unknown|  5|     no|      54|secondary|    yes|    services|  no| married|  may|   -1| unknown|       0| no|\n",
      "+---+-------+--------+-------+---+-------+--------+---------+-------+------------+----+--------+-----+-----+--------+--------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if the data has dictionary with key- value pairs are seperated by newline the we use multiLine = True\n",
    "\n",
    "bank_data = spark.read.json(\"file:///home/hadoop/Downloads/bank_edited.json\", multiLine=True)\n",
    "bank_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "354ba972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- balance: long (nullable = true)\n",
      " |-- campaign: long (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: long (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- duration: long (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- pdays: long (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- previous: long (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bank_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85426ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType, FloatType, StringType, StructType, StructField\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018fd1bd",
   "metadata": {},
   "source": [
    "#### 2. Typecasting any one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42512ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, balance: bigint, campaign: bigint, contact: string, day: bigint, default: string, duration: bigint, education: string, housing: string, job: string, loan: string, marital: string, month: string, pdays: bigint, poutcome: string, previous: bigint, y: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Typecasting age from long to int\n",
    "# we use withColumn for any transformation of the table\n",
    "bank_data.withColumn('age',col('age').cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82368218",
   "metadata": {},
   "source": [
    "#### 3. creating new column from two strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01ca95ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------+------+---------+---------+------------+\n",
      "| id|first_name|last_name|gender|salary|     city|  country|   Full Name|\n",
      "+---+----------+---------+------+------+---------+---------+------------+\n",
      "|  1|     Valma|     Sans|Female|983107|Mulyosari|Indonesia|  Valma Sans|\n",
      "|  2|     Paolo|   Kiddie|  Male|649173|  Niihama|    Japan|Paolo Kiddie|\n",
      "+---+----------+---------+------+------+---------+---------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lit() used for adding literal values, here adding space between firstname and last name\n",
    "\n",
    "from pyspark.sql.functions import concat\n",
    "\n",
    "people_df.withColumn('Full Name',concat(col('first_name'),lit(\" \"),col('last_name'))).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0ab442",
   "metadata": {},
   "source": [
    "#### 4. Renaming existing column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2508e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df = people_df.withColumnRenamed(\"salary\",\"income\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81a81df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, first_name: string, last_name: string, gender: string, income: bigint, city: string, country: string]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4374b7f",
   "metadata": {},
   "source": [
    "#### 5. Limit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8296a620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------+------+---------+-----------+\n",
      "| id|first_name|last_name|gender|income|     city|    country|\n",
      "+---+----------+---------+------+------+---------+-----------+\n",
      "|  1|     Valma|     Sans|Female|983107|Mulyosari|  Indonesia|\n",
      "|  2|     Paolo|   Kiddie|  Male|649173|  Niihama|      Japan|\n",
      "|  3|    Miltie| De Zuani|  Male|352898|Dū Qal‘ah|Afghanistan|\n",
      "|  4|    Jarrid| Dalziell|  Male|170398|   Iberia|       Peru|\n",
      "|  5| Reinaldos|   Keeffe|  Male|440989| La Ronge|     Canada|\n",
      "+---+----------+---------+------+------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df.limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f5ceea",
   "metadata": {},
   "source": [
    "####  OrderBy()\n",
    "\n",
    "    * Arrange data in ascending or descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90837045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------+------+------------+---------+\n",
      "| id|first_name|last_name|gender|income|        city|  country|\n",
      "+---+----------+---------+------+------+------------+---------+\n",
      "| 93|      Cory|    Prigg|  Male| 12876|     Gondang|Indonesia|\n",
      "|590|      Flem| Tumielli|  Male| 13347| Debre Zeyit| Ethiopia|\n",
      "|192|       Odo|  Conyers|  Male| 15555|  Raffingora| Zimbabwe|\n",
      "|407|  Barbabas|Ballingal|  Male| 18598|Beringinjaya|Indonesia|\n",
      "|297|     Daron|   Melato|Female| 19881|      Phayao| Thailand|\n",
      "+---+----------+---------+------+------+------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df.orderBy([\"income\"],ascending=True).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65fd1d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------+------+-------------+-------------+\n",
      "| id|first_name|last_name|gender|income|         city|      country|\n",
      "+---+----------+---------+------+------+-------------+-------------+\n",
      "|490|  Cathlene| Gatfield|Female|981605|      Mīrābād|  Afghanistan|\n",
      "|448|      Yuri|  Duggary|  Male|414107|Sang-e Māshah|  Afghanistan|\n",
      "|  3|    Miltie| De Zuani|  Male|352898|    Dū Qal‘ah|  Afghanistan|\n",
      "|155|    Guntar| Langmuir|  Male|290613|        Khōst|  Afghanistan|\n",
      "|983|      Tiff|  Dreakin|Female|208548|        Āsmār|  Afghanistan|\n",
      "|290|     Myles|   Britch|  Male|191508|    Dū Laīnah|  Afghanistan|\n",
      "|419|   Ezekiel|Fleetwood|  Male|163113| Barakī Barak|  Afghanistan|\n",
      "|701|    Gerrie|   Heigho|  Male|503327|        Föglö|Aland Islands|\n",
      "|674|    Ludwig| Bothwell|  Male|825171|    Martanesh|      Albania|\n",
      "|421|    Hamnet|  Maruska|  Male|129628|      Hoçisht|      Albania|\n",
      "+---+----------+---------+------+------+-------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df.orderBy([\"country\",\"income\"],ascending=[True,False]).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8ebaef",
   "metadata": {},
   "source": [
    "#### Materialized view\n",
    "    * createOrReplaceTempView()\n",
    "    * we use this because we cannot make changes to original warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "949846c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data.createOrReplaceTempView('bankdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9edd0afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+-------+---+-------+--------+---------+-------+------------+----+-------+-----+-----+--------+--------+---+\n",
      "|age|balance|campaign|contact|day|default|duration|education|housing|         job|loan|marital|month|pdays|poutcome|previous|  y|\n",
      "+---+-------+--------+-------+---+-------+--------+---------+-------+------------+----+-------+-----+-----+--------+--------+---+\n",
      "| 58|   2143|       1|unknown|  5|     no|     261| tertiary|    yes|  management|  no|married|  may|   -1| unknown|       0| no|\n",
      "| 44|     29|       1|unknown|  5|     no|     151|secondary|    yes|  technician|  no| single|  may|   -1| unknown|       0| no|\n",
      "| 33|      2|       1|unknown|  5|     no|      76|secondary|    yes|entrepreneur| yes|married|  may|   -1| unknown|       0| no|\n",
      "| 47|   1506|       1|unknown|  5|     no|      92|  unknown|    yes| blue-collar|  no|married|  may|   -1| unknown|       0| no|\n",
      "| 33|      1|       1|unknown|  5|     no|     198|  unknown|     no|     unknown|  no| single|  may|   -1| unknown|       0| no|\n",
      "+---+-------+--------+-------+---+-------+--------+---------+-------+------------+----+-------+-----+-----+--------+--------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from bankdata\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16badc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|45211|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) as count from bankdata\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9b5d1d",
   "metadata": {},
   "source": [
    "*  Show the top 10 Youngest age group  with maximum balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "896fff43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+\n",
      "|age|max(balance)|\n",
      "+---+------------+\n",
      "| 18|        1944|\n",
      "| 19|        5368|\n",
      "| 20|        8860|\n",
      "| 21|        8278|\n",
      "| 22|       10971|\n",
      "| 23|       19690|\n",
      "| 24|       23878|\n",
      "| 25|       16874|\n",
      "| 26|       24299|\n",
      "| 27|       24025|\n",
      "+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select age, max(balance) from bankdata group by age order by age asc limit(10)\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae17df0e",
   "metadata": {},
   "source": [
    "* show the worst 5 job type having minimum salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7252f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+\n",
      "|          job|min(balance)|\n",
      "+-------------+------------+\n",
      "|  blue-collar|       -8019|\n",
      "|   management|       -6847|\n",
      "|self-employed|       -3313|\n",
      "|   technician|       -2827|\n",
      "|     services|       -2122|\n",
      "| entrepreneur|       -2082|\n",
      "|    housemaid|       -1941|\n",
      "|       admin.|       -1601|\n",
      "|      retired|       -1598|\n",
      "|   unemployed|       -1270|\n",
      "|      student|        -679|\n",
      "|      unknown|        -295|\n",
      "+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select job, min(balance) from bankdata group by job order by min(balance) asc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c83e9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
